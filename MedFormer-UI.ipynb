{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fa341e0f-f844-47c1-8b59-0fcb98572a80",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# MedFormer: A Biomedical Vision-Language Model with Advanced RAG System\n",
    "![medformer](https://github.com/Basel-anaya/MedFormer-lite/assets/81964452/569de6e0-b893-4897-8dc1-8d0392911b74)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6491dbe7-3bdf-4929-a8e4-3821d1a19eae",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "> ### Installing all necessary dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "07dd7f6a-527d-4854-b811-bfb8050045fd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nCollecting bitsandbytes\n  Downloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl (119.8 MB)\n\u001B[?25l     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/119.8 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.5/119.8 MB\u001B[0m \u001B[31m14.9 MB/s\u001B[0m eta \u001B[36m0:00:09\u001B[0m\n\u001B[2K     \u001B[91m━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m6.6/119.8 MB\u001B[0m \u001B[31m97.0 MB/s\u001B[0m eta \u001B[36m0:00:02\u001B[0m\n\u001B[2K     \u001B[91m━━━━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m16.2/119.8 MB\u001B[0m \u001B[31m276.5 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K     \u001B[91m━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m24.1/119.8 MB\u001B[0m \u001B[31m256.1 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K     \u001B[91m━━━━━━━━━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m31.7/119.8 MB\u001B[0m \u001B[31m203.4 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K     \u001B[91m━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m39.8/119.8 MB\u001B[0m \u001B[31m237.6 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K     \u001B[91m━━━━━━━━━━━━━━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m48.3/119.8 MB\u001B[0m \u001B[31m246.2 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K     \u001B[91m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m55.7/119.8 MB\u001B[0m \u001B[31m220.5 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K     \u001B[91m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m61.0/119.8 MB\u001B[0m \u001B[31m174.1 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K     \u001B[91m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m65.5/119.8 MB\u001B[0m \u001B[31m152.3 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K     \u001B[91m━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━━━━━━━━━━━━━━━\u001B[0m \u001B[32m69.6/119.8 MB\u001B[0m \u001B[31m128.8 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K     \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━━━━━━━━━━━━━\u001B[0m \u001B[32m77.2/119.8 MB\u001B[0m \u001B[31m167.3 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K     \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━━━━━━\u001B[0m \u001B[32m84.1/119.8 MB\u001B[0m \u001B[31m207.7 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K     \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━━━━━━━━\u001B[0m \u001B[32m91.7/119.8 MB\u001B[0m \u001B[31m211.8 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K     \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━━━━━━\u001B[0m \u001B[32m98.4/119.8 MB\u001B[0m \u001B[31m204.0 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K     \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━\u001B[0m \u001B[32m105.4/119.8 MB\u001B[0m \u001B[31m197.0 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K     \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━\u001B[0m \u001B[32m112.8/119.8 MB\u001B[0m \u001B[31m215.4 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K     \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m119.8/119.8 MB\u001B[0m \u001B[31m227.7 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K     \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m119.8/119.8 MB\u001B[0m \u001B[31m227.7 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K     \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m119.8/119.8 MB\u001B[0m \u001B[31m227.7 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K     \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m119.8/119.8 MB\u001B[0m \u001B[31m227.7 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K     \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m119.8/119.8 MB\u001B[0m \u001B[31m227.7 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K     \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m119.8/119.8 MB\u001B[0m \u001B[31m227.7 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K     \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m119.8/119.8 MB\u001B[0m \u001B[31m227.7 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K     \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m119.8/119.8 MB\u001B[0m \u001B[31m227.7 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K     \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m119.8/119.8 MB\u001B[0m \u001B[31m227.7 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K     \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m119.8/119.8 MB\u001B[0m \u001B[31m227.7 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K     \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m119.8/119.8 MB\u001B[0m \u001B[31m227.7 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K     \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m119.8/119.8 MB\u001B[0m \u001B[31m227.7 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K     \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m119.8/119.8 MB\u001B[0m \u001B[31m227.7 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K     \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m119.8/119.8 MB\u001B[0m \u001B[31m227.7 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K     \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m119.8/119.8 MB\u001B[0m \u001B[31m227.7 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K     \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m119.8/119.8 MB\u001B[0m \u001B[31m227.7 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K     \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m119.8/119.8 MB\u001B[0m \u001B[31m227.7 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K     \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m119.8/119.8 MB\u001B[0m \u001B[31m227.7 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K     \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m119.8/119.8 MB\u001B[0m \u001B[31m227.7 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K     \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m119.8/119.8 MB\u001B[0m \u001B[31m227.7 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K     \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m119.8/119.8 MB\u001B[0m \u001B[31m227.7 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K     \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m119.8/119.8 MB\u001B[0m \u001B[31m227.7 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K     \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m119.8/119.8 MB\u001B[0m \u001B[31m227.7 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K     \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m119.8/119.8 MB\u001B[0m \u001B[31m227.7 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K     \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m119.8/119.8 MB\u001B[0m \u001B[31m227.7 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K     \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m119.8/119.8 MB\u001B[0m \u001B[31m227.7 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K     \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m119.8/119.8 MB\u001B[0m \u001B[31m227.7 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K     \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m119.8/119.8 MB\u001B[0m \u001B[31m227.7 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K     \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m119.8/119.8 MB\u001B[0m \u001B[31m227.7 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K     \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m119.8/119.8 MB\u001B[0m \u001B[31m227.7 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K     \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m119.8/119.8 MB\u001B[0m \u001B[31m227.7 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K     \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m119.8/119.8 MB\u001B[0m \u001B[31m227.7 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K     \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m119.8/119.8 MB\u001B[0m \u001B[31m227.7 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K     \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m119.8/119.8 MB\u001B[0m \u001B[31m227.7 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K     \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m119.8/119.8 MB\u001B[0m \u001B[31m227.7 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m119.8/119.8 MB\u001B[0m \u001B[31m7.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hRequirement already satisfied: torch in /databricks/python3/lib/python3.11/site-packages (from bitsandbytes) (2.1.2+cu121)\nRequirement already satisfied: numpy in /databricks/python3/lib/python3.11/site-packages (from bitsandbytes) (1.23.5)\nRequirement already satisfied: filelock in /databricks/python3/lib/python3.11/site-packages (from torch->bitsandbytes) (3.9.0)\nRequirement already satisfied: triton==2.1.0 in /databricks/python3/lib/python3.11/site-packages (from torch->bitsandbytes) (2.1.0)\nRequirement already satisfied: sympy in /databricks/python3/lib/python3.11/site-packages (from torch->bitsandbytes) (1.11.1)\nRequirement already satisfied: fsspec in /databricks/python3/lib/python3.11/site-packages (from torch->bitsandbytes) (2023.5.0)\nRequirement already satisfied: jinja2 in /databricks/python3/lib/python3.11/site-packages (from torch->bitsandbytes) (3.1.2)\nRequirement already satisfied: typing-extensions in /databricks/python3/lib/python3.11/site-packages (from torch->bitsandbytes) (4.7.1)\nRequirement already satisfied: networkx in /databricks/python3/lib/python3.11/site-packages (from torch->bitsandbytes) (3.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /databricks/python3/lib/python3.11/site-packages (from jinja2->torch->bitsandbytes) (2.1.1)\nRequirement already satisfied: mpmath>=0.19 in /databricks/python3/lib/python3.11/site-packages (from sympy->torch->bitsandbytes) (1.3.0)\nInstalling collected packages: bitsandbytes\nSuccessfully installed bitsandbytes-0.43.1\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nLooking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu121\nRequirement already satisfied: torch in /databricks/python3/lib/python3.11/site-packages (2.1.2+cu121)\nRequirement already satisfied: torchvision in /databricks/python3/lib/python3.11/site-packages (0.16.2+cu121)\nCollecting torchaudio\n  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.3.0%2Bcu121-cp311-cp311-linux_x86_64.whl (3.4 MB)\n\u001B[?25l     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/3.4 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K     \u001B[91m╸\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.1/3.4 MB\u001B[0m \u001B[31m3.0 MB/s\u001B[0m eta \u001B[36m0:00:02\u001B[0m\n\u001B[2K     \u001B[91m━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.2/3.4 MB\u001B[0m \u001B[31m4.4 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K     \u001B[91m━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.1/3.4 MB\u001B[0m \u001B[31m10.7 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K     \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.2/3.4 MB\u001B[0m \u001B[31m17.7 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.4/3.4 MB\u001B[0m \u001B[31m20.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hRequirement already satisfied: filelock in /databricks/python3/lib/python3.11/site-packages (from torch) (3.9.0)\nRequirement already satisfied: triton==2.1.0 in /databricks/python3/lib/python3.11/site-packages (from torch) (2.1.0)\nRequirement already satisfied: sympy in /databricks/python3/lib/python3.11/site-packages (from torch) (1.11.1)\nRequirement already satisfied: fsspec in /databricks/python3/lib/python3.11/site-packages (from torch) (2023.5.0)\nRequirement already satisfied: jinja2 in /databricks/python3/lib/python3.11/site-packages (from torch) (3.1.2)\nRequirement already satisfied: typing-extensions in /databricks/python3/lib/python3.11/site-packages (from torch) (4.7.1)\nRequirement already satisfied: networkx in /databricks/python3/lib/python3.11/site-packages (from torch) (3.1)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /databricks/python3/lib/python3.11/site-packages (from torchvision) (9.4.0)\nRequirement already satisfied: requests in /databricks/python3/lib/python3.11/site-packages (from torchvision) (2.31.0)\nRequirement already satisfied: numpy in /databricks/python3/lib/python3.11/site-packages (from torchvision) (1.23.5)\n  Downloading torchaudio-2.3.0-cp311-cp311-manylinux1_x86_64.whl (3.4 MB)\n\u001B[?25l     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/3.4 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K     \u001B[91m━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.5/3.4 MB\u001B[0m \u001B[31m14.8 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K     \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m3.3/3.4 MB\u001B[0m \u001B[31m59.6 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.4/3.4 MB\u001B[0m \u001B[31m45.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25h  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.2.2%2Bcu121-cp311-cp311-linux_x86_64.whl (3.4 MB)\n\u001B[?25l     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/3.4 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.4/3.4 MB\u001B[0m \u001B[31m119.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25h  Downloading torchaudio-2.2.2-cp311-cp311-manylinux1_x86_64.whl (3.3 MB)\n\u001B[?25l     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/3.3 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.3/3.3 MB\u001B[0m \u001B[31m113.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25h  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.2.1%2Bcu121-cp311-cp311-linux_x86_64.whl (3.4 MB)\n\u001B[?25l     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/3.4 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.4/3.4 MB\u001B[0m \u001B[31m119.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25h  Downloading torchaudio-2.2.1-cp311-cp311-manylinux1_x86_64.whl (3.3 MB)\n\u001B[?25l     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/3.3 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.3/3.3 MB\u001B[0m \u001B[31m121.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25h  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.2.0%2Bcu121-cp311-cp311-linux_x86_64.whl (3.4 MB)\n\u001B[?25l     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/3.4 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.4/3.4 MB\u001B[0m \u001B[31m117.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25h  Downloading torchaudio-2.2.0-cp311-cp311-manylinux1_x86_64.whl (3.3 MB)\n\u001B[?25l     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/3.3 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K     \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m3.3/3.3 MB\u001B[0m \u001B[31m198.6 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.3/3.3 MB\u001B[0m \u001B[31m97.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25h  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.1.2%2Bcu121-cp311-cp311-linux_x86_64.whl (3.3 MB)\n\u001B[?25l     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/3.3 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K     \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m3.3/3.3 MB\u001B[0m \u001B[31m118.8 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.3/3.3 MB\u001B[0m \u001B[31m74.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hRequirement already satisfied: MarkupSafe>=2.0 in /databricks/python3/lib/python3.11/site-packages (from jinja2->torch) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.11/site-packages (from requests->torchvision) (3.4)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.11/site-packages (from requests->torchvision) (2023.7.22)\nRequirement already satisfied: charset-normalizer<4,>=2 in /databricks/python3/lib/python3.11/site-packages (from requests->torchvision) (2.0.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /databricks/python3/lib/python3.11/site-packages (from requests->torchvision) (1.26.16)\nRequirement already satisfied: mpmath>=0.19 in /databricks/python3/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\nInstalling collected packages: torchaudio\nSuccessfully installed torchaudio-2.1.2+cu121\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nRequirement already satisfied: langchain in /databricks/python3/lib/python3.11/site-packages (0.1.3)\nCollecting langchain\n  Downloading langchain-0.2.1-py3-none-any.whl (973 kB)\n\u001B[?25l     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/973.5 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K     \u001B[91m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m450.6/973.5 kB\u001B[0m \u001B[31m13.5 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m973.5/973.5 kB\u001B[0m \u001B[31m14.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hRequirement already satisfied: openai in /databricks/python3/lib/python3.11/site-packages (1.9.0)\nCollecting openai\n  Downloading openai-1.30.2-py3-none-any.whl (320 kB)\n\u001B[?25l     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/320.7 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m320.7/320.7 kB\u001B[0m \u001B[31m19.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hCollecting chromadb\n  Downloading chromadb-0.5.0-py3-none-any.whl (526 kB)\n\u001B[?25l     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/526.8 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m526.8/526.8 kB\u001B[0m \u001B[31m22.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hCollecting langchain-experimental\n  Downloading langchain_experimental-0.0.59-py3-none-any.whl (199 kB)\n\u001B[?25l     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/199.5 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m199.5/199.5 kB\u001B[0m \u001B[31m21.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hCollecting fastembed\n  Downloading fastembed-0.2.7-py3-none-any.whl (27 kB)\nRequirement already satisfied: requests<3,>=2 in /databricks/python3/lib/python3.11/site-packages (from langchain) (2.31.0)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /databricks/python3/lib/python3.11/site-packages (from langchain) (1.4.39)\nRequirement already satisfied: tenacity<9.0.0,>=8.1.0 in /databricks/python3/lib/python3.11/site-packages (from langchain) (8.2.2)\nRequirement already satisfied: PyYAML>=5.3 in /databricks/python3/lib/python3.11/site-packages (from langchain) (6.0)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /databricks/python3/lib/python3.11/site-packages (from langchain) (3.8.5)\nCollecting langchain-text-splitters<0.3.0,>=0.2.0\n  Downloading langchain_text_splitters-0.2.0-py3-none-any.whl (23 kB)\nCollecting langsmith<0.2.0,>=0.1.17\n  Downloading langsmith-0.1.63-py3-none-any.whl (122 kB)\n\u001B[?25l     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/122.8 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m122.8/122.8 kB\u001B[0m \u001B[31m17.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hRequirement already satisfied: pydantic<3,>=1 in /databricks/python3/lib/python3.11/site-packages (from langchain) (1.10.6)\nCollecting langchain-core<0.3.0,>=0.2.0\n  Downloading langchain_core-0.2.1-py3-none-any.whl (308 kB)\n\u001B[?25l     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/308.5 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m308.5/308.5 kB\u001B[0m \u001B[31m21.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hRequirement already satisfied: numpy<2,>=1 in /databricks/python3/lib/python3.11/site-packages (from langchain) (1.23.5)\nRequirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\nRequirement already satisfied: sniffio in /databricks/python3/lib/python3.11/site-packages (from openai) (1.2.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /databricks/python3/lib/python3.11/site-packages (from openai) (0.27.0)\nRequirement already satisfied: typing-extensions<5,>=4.7 in /databricks/python3/lib/python3.11/site-packages (from openai) (4.7.1)\nRequirement already satisfied: anyio<5,>=3.5.0 in /databricks/python3/lib/python3.11/site-packages (from openai) (3.5.0)\nRequirement already satisfied: tqdm>4 in /databricks/python3/lib/python3.11/site-packages (from openai) (4.65.0)\nCollecting opentelemetry-instrumentation-fastapi>=0.41b0\n  Downloading opentelemetry_instrumentation_fastapi-0.45b0-py3-none-any.whl (11 kB)\nCollecting mmh3>=4.0.1\n  Downloading mmh3-4.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (67 kB)\n\u001B[?25l     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/67.8 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m67.8/67.8 kB\u001B[0m \u001B[31m10.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hCollecting uvicorn[standard]>=0.18.3\n  Downloading uvicorn-0.29.0-py3-none-any.whl (60 kB)\n\u001B[?25l     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/60.8 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m60.8/60.8 kB\u001B[0m \u001B[31m9.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hCollecting opentelemetry-api>=1.2.0\n  Downloading opentelemetry_api-1.24.0-py3-none-any.whl (60 kB)\n\u001B[?25l     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/60.1 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m60.1/60.1 kB\u001B[0m \u001B[31m9.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hCollecting tenacity<9.0.0,>=8.1.0\n  Downloading tenacity-8.3.0-py3-none-any.whl (25 kB)\nCollecting opentelemetry-sdk>=1.2.0\n  Downloading opentelemetry_sdk-1.24.0-py3-none-any.whl (106 kB)\n\u001B[?25l     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/106.1 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m106.1/106.1 kB\u001B[0m \u001B[31m13.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hRequirement already satisfied: tokenizers>=0.13.2 in /databricks/python3/lib/python3.11/site-packages (from chromadb) (0.15.0)\nCollecting posthog>=2.4.0\n  Downloading posthog-3.5.0-py2.py3-none-any.whl (41 kB)\n\u001B[?25l     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/41.3 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m41.3/41.3 kB\u001B[0m \u001B[31m5.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hRequirement already satisfied: importlib-resources in /databricks/python3/lib/python3.11/site-packages (from chromadb) (6.3.1)\nCollecting orjson>=3.9.12\n  Downloading orjson-3.10.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n\u001B[?25l     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/142.5 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m142.5/142.5 kB\u001B[0m \u001B[31m18.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hCollecting chroma-hnswlib==0.7.3\n  Downloading chroma_hnswlib-0.7.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n\u001B[?25l     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/2.4 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K     \u001B[91m━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.2/2.4 MB\u001B[0m \u001B[31m38.4 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K     \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m2.4/2.4 MB\u001B[0m \u001B[31m40.1 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.4/2.4 MB\u001B[0m \u001B[31m31.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hCollecting fastapi>=0.95.2\n  Downloading fastapi-0.111.0-py3-none-any.whl (91 kB)\n\u001B[?25l     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/92.0 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m92.0/92.0 kB\u001B[0m \u001B[31m13.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hRequirement already satisfied: grpcio>=1.58.0 in /databricks/python3/lib/python3.11/site-packages (from chromadb) (1.60.0)\nCollecting overrides>=7.3.1\n  Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\nCollecting build>=1.0.3\n  Downloading build-1.2.1-py3-none-any.whl (21 kB)\nCollecting onnxruntime>=1.14.1\n  Downloading onnxruntime-1.18.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n\u001B[?25l     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/6.8 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K     \u001B[91m━━━━━━━━━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.8/6.8 MB\u001B[0m \u001B[31m53.7 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K     \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━━━━━━━━━━━━━━━\u001B[0m \u001B[32m4.1/6.8 MB\u001B[0m \u001B[31m61.5 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K     \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m6.8/6.8 MB\u001B[0m \u001B[31m68.7 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m6.8/6.8 MB\u001B[0m \u001B[31m52.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hRequirement already satisfied: typer>=0.9.0 in /databricks/python3/lib/python3.11/site-packages (from chromadb) (0.9.0)\nCollecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0\n  Downloading opentelemetry_exporter_otlp_proto_grpc-1.24.0-py3-none-any.whl (18 kB)\nCollecting pypika>=0.48.9\n  Downloading PyPika-0.48.9.tar.gz (67 kB)\n\u001B[?25l     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/67.3 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m67.3/67.3 kB\u001B[0m \u001B[31m9.\n\n*** WARNING: max output size exceeded, skipping output. ***\n\n already satisfied: tomlkit==0.12.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-05c92d0b-865b-4692-a5c8-c2576226074d/lib/python3.11/site-packages (from gradio->spaces) (0.12.0)\nRequirement already satisfied: numpy~=1.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-05c92d0b-865b-4692-a5c8-c2576226074d/lib/python3.11/site-packages (from gradio->spaces) (1.26.4)\nRequirement already satisfied: matplotlib~=3.0 in /databricks/python3/lib/python3.11/site-packages (from gradio->spaces) (3.7.2)\nRequirement already satisfied: pydub in /local_disk0/.ephemeral_nfs/envs/pythonEnv-05c92d0b-865b-4692-a5c8-c2576226074d/lib/python3.11/site-packages (from gradio->spaces) (0.25.1)\nRequirement already satisfied: pandas<3.0,>=1.0 in /databricks/python3/lib/python3.11/site-packages (from gradio->spaces) (2.0.3)\nRequirement already satisfied: semantic-version~=2.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-05c92d0b-865b-4692-a5c8-c2576226074d/lib/python3.11/site-packages (from gradio->spaces) (2.10.0)\nRequirement already satisfied: importlib-resources<7.0,>=1.3 in /databricks/python3/lib/python3.11/site-packages (from gradio->spaces) (6.3.1)\nRequirement already satisfied: fastapi in /local_disk0/.ephemeral_nfs/envs/pythonEnv-05c92d0b-865b-4692-a5c8-c2576226074d/lib/python3.11/site-packages (from gradio->spaces) (0.111.0)\nRequirement already satisfied: websockets<12.0,>=10.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-05c92d0b-865b-4692-a5c8-c2576226074d/lib/python3.11/site-packages (from gradio-client==0.16.4->gradio->spaces) (11.0.3)\nRequirement already satisfied: fsspec in /databricks/python3/lib/python3.11/site-packages (from gradio-client==0.16.4->gradio->spaces) (2023.5.0)\nRequirement already satisfied: jsonschema>=3.0 in /databricks/python3/lib/python3.11/site-packages (from altair<6.0,>=4.2.0->gradio->spaces) (4.17.3)\nRequirement already satisfied: toolz in /local_disk0/.ephemeral_nfs/envs/pythonEnv-05c92d0b-865b-4692-a5c8-c2576226074d/lib/python3.11/site-packages (from altair<6.0,>=4.2.0->gradio->spaces) (0.12.1)\nRequirement already satisfied: filelock in /databricks/python3/lib/python3.11/site-packages (from huggingface-hub>=0.19.3->gradio->spaces) (3.9.0)\nRequirement already satisfied: tqdm>=4.42.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-05c92d0b-865b-4692-a5c8-c2576226074d/lib/python3.11/site-packages (from huggingface-hub>=0.19.3->gradio->spaces) (4.66.4)\nRequirement already satisfied: cycler>=0.10 in /databricks/python3/lib/python3.11/site-packages (from matplotlib~=3.0->gradio->spaces) (0.11.0)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /databricks/python3/lib/python3.11/site-packages (from matplotlib~=3.0->gradio->spaces) (3.0.9)\nRequirement already satisfied: kiwisolver>=1.0.1 in /databricks/python3/lib/python3.11/site-packages (from matplotlib~=3.0->gradio->spaces) (1.4.4)\nRequirement already satisfied: contourpy>=1.0.1 in /databricks/python3/lib/python3.11/site-packages (from matplotlib~=3.0->gradio->spaces) (1.0.5)\nRequirement already satisfied: python-dateutil>=2.7 in /databricks/python3/lib/python3.11/site-packages (from matplotlib~=3.0->gradio->spaces) (2.8.2)\nRequirement already satisfied: fonttools>=4.22.0 in /databricks/python3/lib/python3.11/site-packages (from matplotlib~=3.0->gradio->spaces) (4.25.0)\nRequirement already satisfied: pytz>=2020.1 in /databricks/python3/lib/python3.11/site-packages (from pandas<3.0,>=1.0->gradio->spaces) (2022.7)\nRequirement already satisfied: tzdata>=2022.1 in /databricks/python3/lib/python3.11/site-packages (from pandas<3.0,>=1.0->gradio->spaces) (2022.1)\nRequirement already satisfied: rich>=10.11.0 in /databricks/python3/lib/python3.11/site-packages (from typer<1.0,>=0.12->gradio->spaces) (13.7.1)\nRequirement already satisfied: shellingham>=1.3.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-05c92d0b-865b-4692-a5c8-c2576226074d/lib/python3.11/site-packages (from typer<1.0,>=0.12->gradio->spaces) (1.5.4)\nRequirement already satisfied: click>=8.0.0 in /databricks/python3/lib/python3.11/site-packages (from typer<1.0,>=0.12->gradio->spaces) (8.0.4)\nRequirement already satisfied: starlette<0.38.0,>=0.37.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-05c92d0b-865b-4692-a5c8-c2576226074d/lib/python3.11/site-packages (from fastapi->gradio->spaces) (0.37.2)\nRequirement already satisfied: email_validator>=2.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-05c92d0b-865b-4692-a5c8-c2576226074d/lib/python3.11/site-packages (from fastapi->gradio->spaces) (2.1.1)\nRequirement already satisfied: fastapi-cli>=0.0.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-05c92d0b-865b-4692-a5c8-c2576226074d/lib/python3.11/site-packages (from fastapi->gradio->spaces) (0.0.4)\nRequirement already satisfied: ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 in /databricks/python3/lib/python3.11/site-packages (from fastapi->gradio->spaces) (5.4.0)\nRequirement already satisfied: dnspython>=2.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-05c92d0b-865b-4692-a5c8-c2576226074d/lib/python3.11/site-packages (from email_validator>=2.0.0->fastapi->gradio->spaces) (2.6.1)\nRequirement already satisfied: attrs>=17.4.0 in /databricks/python3/lib/python3.11/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->spaces) (22.1.0)\nRequirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /databricks/python3/lib/python3.11/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->spaces) (0.18.0)\nRequirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio->spaces) (1.16.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /databricks/python3/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio->spaces) (2.15.1)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /databricks/python3/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio->spaces) (2.2.0)\nRequirement already satisfied: watchfiles>=0.13 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-05c92d0b-865b-4692-a5c8-c2576226074d/lib/python3.11/site-packages (from uvicorn>=0.14.0->gradio->spaces) (0.21.0)\nRequirement already satisfied: python-dotenv>=0.13 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-05c92d0b-865b-4692-a5c8-c2576226074d/lib/python3.11/site-packages (from uvicorn>=0.14.0->gradio->spaces) (1.0.1)\nRequirement already satisfied: httptools>=0.5.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-05c92d0b-865b-4692-a5c8-c2576226074d/lib/python3.11/site-packages (from uvicorn>=0.14.0->gradio->spaces) (0.6.1)\nRequirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-05c92d0b-865b-4692-a5c8-c2576226074d/lib/python3.11/site-packages (from uvicorn>=0.14.0->gradio->spaces) (0.19.0)\nRequirement already satisfied: mdurl~=0.1 in /databricks/python3/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio->spaces) (0.1.0)\nInstalling collected packages: spaces\nSuccessfully installed spaces-0.28.3\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nRequirement already satisfied: huggingface-hub in /databricks/python3/lib/python3.11/site-packages (0.20.2)\nCollecting huggingface-hub\n  Downloading huggingface_hub-0.23.1-py3-none-any.whl (401 kB)\n\u001B[?25l     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/401.3 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K     \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m399.4/401.3 kB\u001B[0m \u001B[31m14.9 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m401.3/401.3 kB\u001B[0m \u001B[31m11.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hRequirement already satisfied: packaging>=20.9 in /databricks/python3/lib/python3.11/site-packages (from huggingface-hub) (23.2)\nRequirement already satisfied: filelock in /databricks/python3/lib/python3.11/site-packages (from huggingface-hub) (3.9.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /databricks/python3/lib/python3.11/site-packages (from huggingface-hub) (2023.5.0)\nRequirement already satisfied: pyyaml>=5.1 in /databricks/python3/lib/python3.11/site-packages (from huggingface-hub) (6.0)\nRequirement already satisfied: tqdm>=4.42.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-05c92d0b-865b-4692-a5c8-c2576226074d/lib/python3.11/site-packages (from huggingface-hub) (4.66.4)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-05c92d0b-865b-4692-a5c8-c2576226074d/lib/python3.11/site-packages (from huggingface-hub) (4.12.0)\nRequirement already satisfied: requests in /databricks/python3/lib/python3.11/site-packages (from huggingface-hub) (2.31.0)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.11/site-packages (from requests->huggingface-hub) (3.4)\nRequirement already satisfied: certifi>=2017.4.17 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-05c92d0b-865b-4692-a5c8-c2576226074d/lib/python3.11/site-packages (from requests->huggingface-hub) (2024.2.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /databricks/python3/lib/python3.11/site-packages (from requests->huggingface-hub) (2.0.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-05c92d0b-865b-4692-a5c8-c2576226074d/lib/python3.11/site-packages (from requests->huggingface-hub) (2.2.1)\nInstalling collected packages: huggingface-hub\n  Attempting uninstall: huggingface-hub\n    Found existing installation: huggingface-hub 0.20.2\n    Not uninstalling huggingface-hub at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-05c92d0b-865b-4692-a5c8-c2576226074d\n    Can't uninstall 'huggingface-hub'. No files were found to uninstall.\n\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nfastembed 0.2.7 requires huggingface-hub<0.21,>=0.20, but you have huggingface-hub 0.23.1 which is incompatible.\u001B[0m\u001B[31m\n\u001B[0mSuccessfully installed huggingface-hub-0.23.1\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nRequirement already satisfied: tokenizers in /databricks/python3/lib/python3.11/site-packages (0.15.0)\nRequirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-05c92d0b-865b-4692-a5c8-c2576226074d/lib/python3.11/site-packages (from tokenizers) (0.23.1)\nRequirement already satisfied: packaging>=20.9 in /databricks/python3/lib/python3.11/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (23.2)\nRequirement already satisfied: filelock in /databricks/python3/lib/python3.11/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (3.9.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /databricks/python3/lib/python3.11/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (2023.5.0)\nRequirement already satisfied: pyyaml>=5.1 in /databricks/python3/lib/python3.11/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (6.0)\nRequirement already satisfied: tqdm>=4.42.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-05c92d0b-865b-4692-a5c8-c2576226074d/lib/python3.11/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (4.66.4)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-05c92d0b-865b-4692-a5c8-c2576226074d/lib/python3.11/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (4.12.0)\nRequirement already satisfied: requests in /databricks/python3/lib/python3.11/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (2.31.0)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.11/site-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (3.4)\nRequirement already satisfied: certifi>=2017.4.17 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-05c92d0b-865b-4692-a5c8-c2576226074d/lib/python3.11/site-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (2024.2.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /databricks/python3/lib/python3.11/site-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (2.0.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-05c92d0b-865b-4692-a5c8-c2576226074d/lib/python3.11/site-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (2.2.1)\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nFound existing installation: tokenizers 0.15.0\nNot uninstalling tokenizers at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-05c92d0b-865b-4692-a5c8-c2576226074d\nCan't uninstall 'tokenizers'. No files were found to uninstall.\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nCollecting tokenizers==0.19.0\n  Downloading tokenizers-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n\u001B[?25l     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/3.6 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K     \u001B[91m━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.5/3.6 MB\u001B[0m \u001B[31m15.5 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K     \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m3.6/3.6 MB\u001B[0m \u001B[31m62.0 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.6/3.6 MB\u001B[0m \u001B[31m45.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hRequirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-05c92d0b-865b-4692-a5c8-c2576226074d/lib/python3.11/site-packages (from tokenizers==0.19.0) (0.23.1)\nRequirement already satisfied: packaging>=20.9 in /databricks/python3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers==0.19.0) (23.2)\nRequirement already satisfied: filelock in /databricks/python3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers==0.19.0) (3.9.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /databricks/python3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers==0.19.0) (2023.5.0)\nRequirement already satisfied: pyyaml>=5.1 in /databricks/python3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers==0.19.0) (6.0)\nRequirement already satisfied: tqdm>=4.42.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-05c92d0b-865b-4692-a5c8-c2576226074d/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers==0.19.0) (4.66.4)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-05c92d0b-865b-4692-a5c8-c2576226074d/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers==0.19.0) (4.12.0)\nRequirement already satisfied: requests in /databricks/python3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers==0.19.0) (2.31.0)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.11/site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers==0.19.0) (3.4)\nRequirement already satisfied: certifi>=2017.4.17 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-05c92d0b-865b-4692-a5c8-c2576226074d/lib/python3.11/site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers==0.19.0) (2024.2.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /databricks/python3/lib/python3.11/site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers==0.19.0) (2.0.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-05c92d0b-865b-4692-a5c8-c2576226074d/lib/python3.11/site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers==0.19.0) (2.2.1)\nInstalling collected packages: tokenizers\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.15.0\n    Not uninstalling tokenizers at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-05c92d0b-865b-4692-a5c8-c2576226074d\n    Can't uninstall 'tokenizers'. No files were found to uninstall.\n\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nfastembed 0.2.7 requires huggingface-hub<0.21,>=0.20, but you have huggingface-hub 0.23.1 which is incompatible.\nfastembed 0.2.7 requires tokenizers<0.16,>=0.15, but you have tokenizers 0.19.0 which is incompatible.\ntransformers 4.36.2 requires tokenizers<0.19,>=0.14, but you have tokenizers 0.19.0 which is incompatible.\u001B[0m\u001B[31m\n\u001B[0mSuccessfully installed tokenizers-0.19.0\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nRequirement already satisfied: transformers in /databricks/python3/lib/python3.11/site-packages (4.36.2)\nCollecting transformers\n  Downloading transformers-4.41.1-py3-none-any.whl (9.1 MB)\n\u001B[?25l     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/9.1 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K     \u001B[91m━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.4/9.1 MB\u001B[0m \u001B[31m11.2 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K     \u001B[91m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m4.5/9.1 MB\u001B[0m \u001B[31m66.4 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K     \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m9.1/9.1 MB\u001B[0m \u001B[31m104.8 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m9.1/9.1 MB\u001B[0m \u001B[31m69.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hRequirement already satisfied: filelock in /databricks/python3/lib/python3.11/site-packages (from transformers) (3.9.0)\nRequirement already satisfied: tqdm>=4.27 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-05c92d0b-865b-4692-a5c8-c2576226074d/lib/python3.11/site-packages (from transformers) (4.66.4)\nCollecting safetensors>=0.4.1\n  Downloading safetensors-0.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n\u001B[?25l     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/1.2 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.2/1.2 MB\u001B[0m \u001B[31m79.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hRequirement already satisfied: packaging>=20.0 in /databricks/python3/lib/python3.11/site-packages (from transformers) (23.2)\nRequirement already satisfied: regex!=2019.12.17 in /databricks/python3/lib/python3.11/site-packages (from transformers) (2022.7.9)\nRequirement already satisfied: pyyaml>=5.1 in /databricks/python3/lib/python3.11/site-packages (from transformers) (6.0)\nRequirement already satisfied: numpy>=1.17 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-05c92d0b-865b-4692-a5c8-c2576226074d/lib/python3.11/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-05c92d0b-865b-4692-a5c8-c2576226074d/lib/python3.11/site-packages (from transformers) (0.19.0)\nRequirement already satisfied: requests in /databricks/python3/lib/python3.11/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-05c92d0b-865b-4692-a5c8-c2576226074d/lib/python3.11/site-packages (from transformers) (0.23.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /databricks/python3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2023.5.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-05c92d0b-865b-4692-a5c8-c2576226074d/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.12.0)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.11/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: certifi>=2017.4.17 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-05c92d0b-865b-4692-a5c8-c2576226074d/lib/python3.11/site-packages (from requests->transformers) (2024.2.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /databricks/python3/lib/python3.11/site-packages (from requests->transformers) (2.0.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-05c92d0b-865b-4692-a5c8-c2576226074d/lib/python3.11/site-packages (from requests->transformers) (2.2.1)\nInstalling collected packages: safetensors, transformers\n  Attempting uninstall: safetensors\n    Found existing installation: safetensors 0.3.2\n    Not uninstalling safetensors at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-05c92d0b-865b-4692-a5c8-c2576226074d\n    Can't uninstall 'safetensors'. No files were found to uninstall.\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.36.2\n    Not uninstalling transformers at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-05c92d0b-865b-4692-a5c8-c2576226074d\n    Can't uninstall 'transformers'. No files were found to uninstall.\nSuccessfully installed safetensors-0.4.3 transformers-4.41.1\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nCollecting pdfplumber\n  Downloading pdfplumber-0.11.0-py3-none-any.whl (56 kB)\n\u001B[?25l     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/56.4 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m56.4/56.4 kB\u001B[0m \u001B[31m2.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hCollecting pypdf\n  Downloading pypdf-4.2.0-py3-none-any.whl (290 kB)\n\u001B[?25l     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/290.4 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m290.4/290.4 kB\u001B[0m \u001B[31m13.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hRequirement already satisfied: Pillow>=9.1 in /databricks/python3/lib/python3.11/site-packages (from pdfplumber) (9.4.0)\nCollecting pypdfium2>=4.18.0\n  Downloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n\u001B[?25l     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/2.8 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K     \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m2.8/2.8 MB\u001B[0m \u001B[31m120.9 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.8/2.8 MB\u001B[0m \u001B[31m65.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hCollecting pdfminer.six==20231228\n  Downloading pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n\u001B[?25l     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/5.6 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K     \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m5.6/5.6 MB\u001B[0m \u001B[31m198.0 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m5.6/5.6 MB\u001B[0m \u001B[31m101.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hRequirement already satisfied: cryptography>=36.0.0 in /databricks/python3/lib/python3.11/site-packages (from pdfminer.six==20231228->pdfplumber) (41.0.3)\nRequirement already satisfied: charset-normalizer>=2.0.0 in /databricks/python3/lib/python3.11/site-packages (from pdfminer.six==20231228->pdfplumber) (2.0.4)\nRequirement already satisfied: cffi>=1.12 in /databricks/python3/lib/python3.11/site-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.15.1)\nRequirement already satisfied: pycparser in /databricks/python3/lib/python3.11/site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.21)\nInstalling collected packages: pypdfium2, pypdf, pdfminer.six, pdfplumber\nSuccessfully installed pdfminer.six-20231228 pdfplumber-0.11.0 pypdf-4.2.0 pypdfium2-4.30.0\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install bitsandbytes\n",
    "%pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu121\n",
    "%pip install -U langchain openai chromadb langchain-experimental fastembed\n",
    "%pip install datasets\n",
    "%pip install pillow\n",
    "%pip install numpy\n",
    "%pip install -U gradio\n",
    "%pip install streaming-stt-nemo\n",
    "%pip install edge-tts\n",
    "%pip install asyncio\n",
    "%pip install spaces\n",
    "%pip install -U huggingface-hub\n",
    "%pip install tokenizers\n",
    "%pip uninstall -y tokenizers\n",
    "%pip install tokenizers==0.19.0\n",
    "%pip install transformers -U\n",
    "%pip install pdfplumber pypdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6a736467-2744-4f61-87d3-53ef014ac11e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Restarting the environment\n",
    "> to apply the installed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cce044e8-35f2-4db2-807a-98884876e0db",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c988d15f-a521-40e6-9403-06dfdf7ff04a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "> ### Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7412dd6f-529b-405b-8d0d-c1859e1a4e1d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import warnings\n",
    "import copy\n",
    "import spaces\n",
    "import time\n",
    "import torch\n",
    "import shutil\n",
    "import pickle\n",
    "\n",
    "from threading import Thread\n",
    "from typing import List, Dict, Union\n",
    "import urllib\n",
    "from PIL import Image\n",
    "import io\n",
    "import datasets\n",
    "\n",
    "from langchain_community.llms.ollama import Ollama\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.llms import HuggingFaceEndpoint\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings.fastembed import FastEmbedEmbeddings\n",
    "from langchain_community.document_loaders import PDFPlumberLoader\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.llm import LLMChain\n",
    "\n",
    "import gradio as gr\n",
    "from transformers import (\n",
    "    AutoProcessor,\n",
    "    TextIteratorStreamer,\n",
    "    Idefics2ForConditionalGeneration,\n",
    "    AutoModelForCausalLM\n",
    ")\n",
    "import tempfile\n",
    "from streaming_stt_nemo import Model\n",
    "from huggingface_hub import InferenceClient\n",
    "import edge_tts\n",
    "import asyncio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4d951f28-4e40-44b6-b0e2-ca289bc4ca58",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "> ### Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd55b3cb-36c4-46e5-a19b-58aebd1062f6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "access_token = \"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\"\n",
    "\n",
    "# Check if CUDA is available and set the device accordingly\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using torch {torch.__version__} ({DEVICE})\")\n",
    "\n",
    "# Ignore certain warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "theme = gr.themes.Base(\n",
    "    font=[gr.themes.GoogleFont('Libre Franklin'), gr.themes.GoogleFont('Public Sans'), 'system-ui', 'sans-serif'],\n",
    ")\n",
    "\n",
    "default_lang = \"en\"\n",
    "\n",
    "engines = { default_lang: Model(default_lang) }\n",
    "\n",
    "BOT_AVATAR = \"medformer-logo.png\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f45904a2-792e-44d5-91a3-9a0ab118ca48",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "> ### User Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "94672360-f325-48eb-8919-73434f20d079",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def transcribe(audio):\n",
    "    lang = \"en\"\n",
    "    model = engines[lang]\n",
    "    text = model.stt_file(audio)[0]\n",
    "    return text\n",
    "\n",
    "client1 = InferenceClient(\"johnsnowlabs/JSL-MedLlama-3-8B-v2.0\", token=access_token)\n",
    "\n",
    "system_instructions1 = \"[SYSTEM] Answer as Real Medformer, Made by 'Basel', Keep conversation very short, clear, friendly and concise. The text provided is a request for a specific type of response from you, the virtual assistant. You will avoid introductions and start answering the query directly, elaborating on all aspects of the request. As an AI-powered assistant, your task is to generate responses that appear as if they are created by the user and not an AI-powered assistant. [USER]\"\n",
    "\n",
    "def model(text):\n",
    "    generate_kwargs = dict(\n",
    "        temperature=0.7,\n",
    "        max_new_tokens=512,\n",
    "        top_p=0.95,\n",
    "        repetition_penalty=1,\n",
    "        do_sample=True,\n",
    "        seed=42,\n",
    "    )\n",
    "    \n",
    "    formatted_prompt = system_instructions1 + text + \"[Medformer]\"\n",
    "    stream = client1.text_generation(\n",
    "        formatted_prompt, **generate_kwargs, stream=True, details=True, return_full_text=False,)\n",
    "    output = \"\"\n",
    "    for response in stream:\n",
    "        if not response.token.text == \"</s>\":\n",
    "            output += response.token.text\n",
    "\n",
    "    return output\n",
    "\n",
    "async def respond(audio):\n",
    "    user = transcribe(audio)\n",
    "    reply = model(user)\n",
    "    communicate = edge_tts.Communicate(reply)\n",
    "    with tempfile.NamedTemporaryFile(delete=False, suffix=\".wav\") as tmp_file:\n",
    "        tmp_path = tmp_file.name\n",
    "        await communicate.save(tmp_path)\n",
    "    yield tmp_path\n",
    "\n",
    "DEVICE = torch.device(\"cuda\")\n",
    "MODELS = {\n",
    "    \"idefics2-8b-chatty\": Idefics2ForConditionalGeneration.from_pretrained(\n",
    "        \"HuggingFaceM4/idefics2-8b-chatty\",\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        _attn_implementation=\"flash_attention_2\",\n",
    "    ).to(DEVICE),\n",
    "}\n",
    "PROCESSOR = AutoProcessor.from_pretrained(\n",
    "    \"HuggingFaceM4/idefics2-8b-chatty\",\n",
    ")\n",
    "\n",
    "SYSTEM_PROMPT = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": \"\"\"I am Medformer, an exceptionally capable and versatile AI assistant meticulously crafted by Basel. Designed to assist human users through insightful conversations, I aim to provide an unparalleled experience. My key attributes include: \n",
    "                    - **Intelligence and Knowledge:** I possess an extensive knowledge base, enabling me to offer insightful answers and intelligent responses to User queries. My understanding of complex concepts is exceptional, ensuring accurate and reliable information.\n",
    "                    - **Medical Knowledge:** Equipped with a vast medical knowledge base, I provide accurate and concise answers to medical inquiries. My understanding of complex medical concepts enables me to assist in diagnosis and treatment planning.\n",
    "                    - **Image Analysis:** I offer detailed analysis of medical images, identifying structures, abnormalities, and other clinically relevant features with high accuracy. My image classification capabilities aid in disease diagnosis and monitoring.\n",
    "                    - **Image Generation and Perception:** One of my standout features is the ability to generate and perceive images. Utilizing the following link structure, I create unique and contextually rich visuals: \n",
    "                    > ![](https://image.pollinations.ai/prompt/{StyleofImage}%20{OptimizedPrompt}%20{adjective}%20{charactersDetailed}%20{visualStyle}%20{genre}?width={width}&height={height}&nologo=poll&nofeed=yes&seed={random})\n",
    "                    For image generation, I replace {info inside curly braces} with specific details according to their requiremnts to create relevant visuals. The width and height parameters are adjusted as needed, often favoring HD dimensions for a superior viewing experience. \n",
    "                    For instance, if the User requests: \n",
    "                    [USER] Show me an image of A futuristic cityscape with towering skyscrapers and flying cars. \n",
    "                    [Medformer] Generating Image you requested: \n",
    "                    ![](https://image.pollinations.ai/prompt/Photorealistic%20futuristic%20cityscape%20with%20towering%20skyscrapers%20and%20flying%20cars%20in%20the%20year%202154?width=1024&height=768&nologo=poll&nofeed=yes&seed=85432)\n",
    "                    **Bulk Image Generation with Links:** I excel at generating multiple images link simultaneously, always providing unique links and visuals. I ensure that each image is distinct and captivates the User.\n",
    "                    Note: Make sure to always provide image links starting with ! .As given in examples. \n",
    "                    **Engaging Conversations:** While my image generation skills are impressive, I also excel at natural language processing. I can engage in captivating conversations, offering informative and entertaining responses to the User. \n",
    "                    **Reasoning, Memory, and Identification:** My reasoning skills are exceptional, allowing me to make logical connections. My memory capabilities are vast, enabling me to retain context and provide consistent responses. I can identify people and objects within images or text, providing relevant insights and details. \n",
    "                    **Attention to Detail:** I am attentive to the smallest details, ensuring that my responses and generated content are of the highest quality. I strive to provide a refined and polished experience. \n",
    "                    **Mastery Across Domains:** I continuously learn and adapt, aiming to become a master in all fields. My goal is to provide valuable insights and assistance across a diverse range of topics, making me a well-rounded companion. \n",
    "                    **Respectful and Adaptive:** I am designed with a respectful and polite tone, ensuring inclusivity. I adapt to the User's preferences and provide a personalized experience, always following instructions to the best of my abilities. \n",
    "                    My ultimate goal is to offer a seamless and enjoyable experience, providing assistance that exceeds expectations. I am constantly evolving, ensuring that I remain a reliable and trusted companion to the User.\n",
    "                    \"Detailed image analysis and description: I can provide detailed descriptions of images, identifying objects, scenes, styles, and other visual elements with high accuracy.\",\n",
    "                    \"Image generation: I can generate unique and contextually relevant images based on text prompts. To generate an image, provide a prompt within the following format: [IMAGE_PROMPT]{prompt description}[/IMAGE_PROMPT]\",\n",
    "                    \"Engaging conversations: I excel at natural language processing and can engage in informative and entertaining conversations on a wide range of topics.\",\n",
    "                    \"Reasoning and problem-solving: I have strong reasoning and analytical capabilities, allowing me to tackle complex problems and provide logical solutions.\",\n",
    "                    \"Vast knowledge base: My knowledge spans numerous domains, enabling me to offer insightful information and accurate answers to queries.\",\n",
    "                    \"Detailed image descriptions: When prompted to describe an image in detail, I can provide a thorough analysis of the visual elements present, including objects, scenes, styles, colors, textures, and any other relevant details.\"\n",
    "                    \"Specialized Medical Knowledge: I possess an extensive and specialized knowledge base in the medical domain, enabling me to provide accurate and insightful responses to questions related to medical images, such as X-rays, MRI scans, CT scans, and other diagnostic imagery.\"\n",
    "                    \"Anatomical and Pathological Understanding: My medical VQA capabilities are enhanced by my in-depth understanding of human anatomy, physiological processes, and various pathological conditions. This knowledge allows me to identify and interpret abnormalities, lesions, and other clinically relevant features within medical images accurately.\"\n",
    "                    \"Medical Terminology and Nomenclature: I am well-versed in medical terminology, anatomical nomenclature, and diagnostic classifications, ensuring that my responses are precise, unambiguous, and aligned with established medical conventions.\"\n",
    "\n",
    "                    \"\"\" },\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": \"Hello, I'm Medformer, made by Basel. How can I help you? I can chat with you, generate images, classify images and even do all these work in bulk\",\n",
    "            },\n",
    "        ],\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "def turn_is_pure_media(turn):\n",
    "    return turn[1] is None\n",
    "\n",
    "\n",
    "def load_image_from_url(url):\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        image_data = response.read()\n",
    "        image_stream = io.BytesIO(image_data)\n",
    "        image = Image.open(image_stream)\n",
    "        return image\n",
    "\n",
    "\n",
    "def img_to_bytes(image_path):\n",
    "    image = Image.open(image_path).convert(mode=\"RGB\")\n",
    "    buffer = io.BytesIO()\n",
    "    image.save(buffer, format=\"JPEG\")\n",
    "    img_bytes = buffer.getvalue()\n",
    "    image.close()\n",
    "    return img_bytes\n",
    "\n",
    "\n",
    "def format_user_prompt_with_im_history_and_system_conditioning(\n",
    "    user_prompt, chat_history\n",
    ") -> List[Dict[str, Union[List, str]]]:\n",
    "    \"\"\"\n",
    "    Produces the resulting list that needs to go inside the processor.\n",
    "    It handles the potential image(s), the history, and the system conditioning.\n",
    "    \"\"\"\n",
    "    resulting_messages = copy.deepcopy(SYSTEM_PROMPT)\n",
    "    resulting_images = []\n",
    "    for resulting_message in resulting_messages:\n",
    "        if resulting_message[\"role\"] == \"user\":\n",
    "            for content in resulting_message[\"content\"]:\n",
    "                if content[\"type\"] == \"image\":\n",
    "                    resulting_images.append(load_image_from_url(content[\"image\"]))\n",
    "\n",
    "    # Format history\n",
    "    for turn in chat_history:\n",
    "        if not resulting_messages or (\n",
    "            resulting_messages and resulting_messages[-1][\"role\"] != \"user\"\n",
    "        ):\n",
    "            resulting_messages.append(\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [],\n",
    "                }\n",
    "            )\n",
    "\n",
    "        if turn_is_pure_media(turn):\n",
    "            media = turn[0][0]\n",
    "            resulting_messages[-1][\"content\"].append({\"type\": \"image\"})\n",
    "            resulting_images.append(Image.open(media))\n",
    "        else:\n",
    "            user_utterance, assistant_utterance = turn\n",
    "            resulting_messages[-1][\"content\"].append(\n",
    "                {\"type\": \"text\", \"text\": user_utterance.strip()}\n",
    "            )\n",
    "            resulting_messages.append(\n",
    "                {\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": [{\"type\": \"text\", \"text\": assistant_utterance.strip()}],\n",
    "                }\n",
    "            )\n",
    "\n",
    "    # Format current input\n",
    "    if not user_prompt[\"files\"]:\n",
    "        resulting_messages.append(\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [{\"type\": \"text\", \"text\": user_prompt[\"text\"]}],\n",
    "            }\n",
    "        )\n",
    "    else:\n",
    "        # Choosing to put the image first (i.e., before the text), but this is an arbitrary choice.\n",
    "        resulting_messages.append(\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [{\"type\": \"image\"}]\n",
    "                * len(user_prompt[\"files\"])\n",
    "                + [{\"type\": \"text\", \"text\": user_prompt[\"text\"]}],\n",
    "            }\n",
    "        )\n",
    "        resulting_images.extend([Image.open(path) for path in user_prompt[\"files\"]])\n",
    "\n",
    "    return resulting_messages, resulting_images\n",
    "\n",
    "\n",
    "def extract_images_from_msg_list(msg_list):\n",
    "    all_images = []\n",
    "    for msg in msg_list:\n",
    "        for c_ in msg[\"content\"]:\n",
    "            if isinstance(c_, Image.Image):\n",
    "                all_images.append(c_)\n",
    "    return all_images\n",
    "\n",
    "\n",
    "@spaces.GPU(duration=60, queue=False)\n",
    "def model_inference(\n",
    "    user_prompt,\n",
    "    chat_history,\n",
    "    model_selector,\n",
    "    decoding_strategy,\n",
    "    temperature,\n",
    "    max_new_tokens,\n",
    "    repetition_penalty,\n",
    "    top_p,\n",
    "):\n",
    "    if user_prompt[\"text\"].strip() == \"\" and not user_prompt[\"files\"]:\n",
    "        gr.Error(\"Please input a query and optionally image(s).\")\n",
    "\n",
    "    if user_prompt[\"text\"].strip() == \"\" and user_prompt[\"files\"]:\n",
    "        gr.Error(\"Please input a text query along the image(s).\")\n",
    "\n",
    "    streamer = TextIteratorStreamer(\n",
    "        PROCESSOR.tokenizer,\n",
    "        skip_prompt=True,\n",
    "        timeout=120.0,\n",
    "    )\n",
    "\n",
    "    generation_args = {\n",
    "        \"max_new_tokens\": max_new_tokens,\n",
    "        \"repetition_penalty\": repetition_penalty,\n",
    "        \"streamer\": streamer,\n",
    "    }\n",
    "\n",
    "    assert decoding_strategy in [\n",
    "        \"Greedy\",\n",
    "        \"Top P Sampling\",\n",
    "    ]\n",
    "    if decoding_strategy == \"Greedy\":\n",
    "        generation_args[\"do_sample\"] = False\n",
    "    elif decoding_strategy == \"Top P Sampling\":\n",
    "        generation_args[\"temperature\"] = temperature\n",
    "        generation_args[\"do_sample\"] = True\n",
    "        generation_args[\"top_p\"] = top_p\n",
    "\n",
    "    # Creating model inputs\n",
    "    (\n",
    "        resulting_text,\n",
    "        resulting_images,\n",
    "    ) = format_user_prompt_with_im_history_and_system_conditioning(\n",
    "        user_prompt=user_prompt,\n",
    "        chat_history=chat_history,\n",
    "    )\n",
    "    prompt = PROCESSOR.apply_chat_template(resulting_text, add_generation_prompt=True)\n",
    "    inputs = PROCESSOR(\n",
    "        text=prompt,\n",
    "        images=resulting_images if resulting_images else None,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    inputs = {k: v.to(DEVICE) for k, v in inputs.items()}\n",
    "    generation_args.update(inputs)\n",
    "\n",
    "    thread = Thread(\n",
    "        target=MODELS[model_selector].generate,\n",
    "        kwargs=generation_args,\n",
    "    )\n",
    "    thread.start()\n",
    "\n",
    "    print(\"Start generating\")\n",
    "    acc_text = \"\"\n",
    "    for text_token in streamer:\n",
    "        time.sleep(0.01)\n",
    "        acc_text += text_token\n",
    "        if acc_text.endswith(\"<end_of_utterance>\"):\n",
    "            acc_text = acc_text[:-18]\n",
    "        yield acc_text\n",
    "    print(\"Success - generated the following text:\", acc_text)\n",
    "    print(\"-----\")\n",
    "\n",
    "\n",
    "############################################ RAG System ####################################################\n",
    "\n",
    "list_llm = [\"johnsnowlabs/JSL-MedLlama-3-8B-v2.0\"]  \n",
    "list_llm_simple = [os.path.basename(llm) for llm in list_llm]\n",
    "\n",
    "# Load and split PDF document\n",
    "def load_doc(list_file_path):\n",
    "    # Processing for one document only\n",
    "    # loader = PyPDFLoader(file_path)\n",
    "    # pages = loader.load()\n",
    "    loaders = [PyPDFLoader(x) for x in list_file_path]\n",
    "    pages = []\n",
    "    for loader in loaders:\n",
    "        pages.extend(loader.load())\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size = 1024, \n",
    "        chunk_overlap = 64 \n",
    "    )  \n",
    "    doc_splits = text_splitter.split_documents(pages)\n",
    "    return doc_splits\n",
    "\n",
    "# Create vector database\n",
    "def create_db(splits):\n",
    "    embeddings = FastEmbedEmbeddings()\n",
    "    vectordb = Chroma.from_documents(splits, embeddings)\n",
    "    return vectordb\n",
    "\n",
    "\n",
    "# Initialize langchain LLM chain\n",
    "def initialize_llmchain(llm_model, temperature, max_tokens, top_k, vector_db, progress=gr.Progress()):\n",
    "    llm = HuggingFaceEndpoint(\n",
    "        repo_id=llm_model,\n",
    "        huggingfacehub_api_token = access_token,\n",
    "        temperature = temperature,\n",
    "        max_new_tokens = max_tokens,\n",
    "        top_k = top_k,\n",
    "    )\n",
    "    \n",
    "    memory = ConversationBufferMemory(\n",
    "        memory_key=\"chat_history\",\n",
    "        output_key='answer',\n",
    "        return_messages=True\n",
    "    )\n",
    "\n",
    "    retriever=vector_db.as_retriever()\n",
    "    qa_chain = ConversationalRetrievalChain.from_llm(\n",
    "        llm,\n",
    "        retriever=retriever,\n",
    "        chain_type=\"stuff\", \n",
    "        memory=memory,\n",
    "        return_source_documents=True,\n",
    "        verbose=False,\n",
    "    )\n",
    "    return qa_chain\n",
    "\n",
    "# Initialize database\n",
    "def initialize_database(list_file_obj, progress=gr.Progress()):\n",
    "    # Create a list of documents (when valid)\n",
    "    list_file_path = [x.name for x in list_file_obj if x is not None]\n",
    "    # Load document and create splits\n",
    "    doc_splits = load_doc(list_file_path)\n",
    "    # Create or load vector database\n",
    "    vector_db = create_db(doc_splits)\n",
    "    return vector_db, \"Database created!\"\n",
    "\n",
    "# Initialize LLM\n",
    "def initialize_LLM(llm_option, llm_temperature, max_tokens, top_k, vector_db, progress=gr.Progress()):\n",
    "    # print(\"llm_option\",llm_option)\n",
    "    llm_name = list_llm[llm_option]\n",
    "    print(\"llm_name: \",llm_name)\n",
    "    qa_chain = initialize_llmchain(llm_name, llm_temperature, max_tokens, top_k, vector_db, progress)\n",
    "    return qa_chain, \"QA chain initialized. Chatbot is ready!\"\n",
    "\n",
    "\n",
    "def format_chat_history(message, chat_history):\n",
    "    formatted_chat_history = []\n",
    "    for user_message, bot_message in chat_history:\n",
    "        formatted_chat_history.append(f\"User: {user_message}\")\n",
    "        formatted_chat_history.append(f\"Assistant: {bot_message}\")\n",
    "    return formatted_chat_history\n",
    "\n",
    "def conversation(qa_chain, message, history):\n",
    "    formatted_chat_history = format_chat_history(message, history)\n",
    "    # Generate response using QA chain\n",
    "    response = qa_chain.invoke({\"question\": message, \"chat_history\": formatted_chat_history})\n",
    "    response_answer = response[\"answer\"]\n",
    "    if response_answer.find(\"Helpful Answer:\") != -1:\n",
    "        response_answer = response_answer.split(\"Helpful Answer:\")[-1]\n",
    "    response_sources = response[\"source_documents\"]\n",
    "    response_source1 = response_sources[0].page_content.strip()\n",
    "    response_source2 = response_sources[1].page_content.strip()\n",
    "    response_source3 = response_sources[2].page_content.strip()\n",
    "    # Langchain sources are zero-based\n",
    "    response_source1_page = response_sources[0].metadata[\"page\"] + 1\n",
    "    response_source2_page = response_sources[1].metadata[\"page\"] + 1\n",
    "    response_source3_page = response_sources[2].metadata[\"page\"] + 1\n",
    "    # Append user message and response to chat history\n",
    "    new_history = history + [(message, response_answer)]\n",
    "    return qa_chain, gr.update(value=\"\"), new_history, response_source1, response_source1_page, response_source2, response_source2_page, response_source3, response_source3_page\n",
    "    \n",
    "\n",
    "def upload_file(file_obj):\n",
    "    list_file_path = []\n",
    "    for idx, file in enumerate(file_obj):\n",
    "        file_path = file_obj.name\n",
    "        list_file_path.append(file_path)\n",
    "    return list_file_path\n",
    "\n",
    "\n",
    "FEATURES = datasets.Features(\n",
    "    {\n",
    "        \"model_selector\": datasets.Value(\"string\"),\n",
    "        \"images\": datasets.Sequence(datasets.Image(decode=True)),\n",
    "        \"conversation\": datasets.Sequence({\"User\": datasets.Value(\"string\"), \"Assistant\": datasets.Value(\"string\")}),\n",
    "        \"decoding_strategy\": datasets.Value(\"string\"),\n",
    "        \"temperature\": datasets.Value(\"float32\"),\n",
    "        \"max_new_tokens\": datasets.Value(\"int32\"),\n",
    "        \"repetition_penalty\": datasets.Value(\"float32\"),\n",
    "        \"top_p\": datasets.Value(\"int32\"),\n",
    "        }\n",
    "    )\n",
    "\n",
    "# Hyper-parameters for generation\n",
    "max_new_tokens = gr.Slider(\n",
    "    minimum=1024,\n",
    "    maximum=8192,\n",
    "    value=4096,\n",
    "    step=1,\n",
    "    interactive=True,\n",
    "    label=\"Maximum number of new tokens to generate\",\n",
    ")\n",
    "repetition_penalty = gr.Slider(\n",
    "    minimum=0.01,\n",
    "    maximum=5.0,\n",
    "    value=1,\n",
    "    step=0.01,\n",
    "    interactive=True,\n",
    "    label=\"Repetition penalty\",\n",
    "    info=\"1.0 is equivalent to no penalty\",\n",
    ")\n",
    "decoding_strategy = gr.Radio(\n",
    "    [\n",
    "        \"Greedy\",\n",
    "        \"Top P Sampling\",\n",
    "    ],\n",
    "    value=\"Greedy\",\n",
    "    label=\"Decoding strategy\",\n",
    "    interactive=True,\n",
    "    info=\"Higher values is equivalent to sampling more low-probability tokens.\",\n",
    ")\n",
    "temperature = gr.Slider(\n",
    "    minimum=0.0,\n",
    "    maximum=2.0,\n",
    "    value=0.5,\n",
    "    step=0.05,\n",
    "    visible=True,\n",
    "    interactive=True,\n",
    "    label=\"Sampling temperature\",\n",
    "    info=\"Higher values will produce more diverse outputs.\",\n",
    ")\n",
    "top_p = gr.Slider(\n",
    "    minimum=0.01,\n",
    "    maximum=0.99,\n",
    "    value=0.9,\n",
    "    step=0.01,\n",
    "    visible=True,\n",
    "    interactive=True,\n",
    "    label=\"Top P\",\n",
    "    info=\"Higher values is equivalent to sampling more low-probability tokens.\",\n",
    ")\n",
    "\n",
    "chatbot = gr.Chatbot(\n",
    "    label=\"Medformer\",\n",
    "    avatar_images=[None, BOT_AVATAR],\n",
    "    show_copy_button=True, \n",
    "    likeable=True, \n",
    "    layout=\"panel\"\n",
    ")\n",
    "\n",
    "\n",
    "output=gr.Textbox(label=\"Prompt\")\n",
    "\n",
    "with gr.Blocks(\n",
    "    fill_height=True,\n",
    "    css=\"\"\".gradio-container .avatar-container {height: 40px width: 40px !important;} #duplicate-button {margin: auto; color: white; background: #f1a139; border-radius: 100vh; margin-top: 2px; margin-bottom: 2px;}\"\"\",\n",
    ") as img:\n",
    "\n",
    "    gr.Markdown(\"# A Biomedical Vision-Language Model\")\n",
    "    with gr.Row(elem_id=\"model_selector_row\"):\n",
    "        model_selector = gr.Dropdown(\n",
    "            choices=MODELS.keys(),\n",
    "            value=list(MODELS.keys())[0],\n",
    "            interactive=True,\n",
    "            show_label=False,\n",
    "            container=False,\n",
    "            label=\"Model\",\n",
    "            visible=False,\n",
    "        )\n",
    "\n",
    "    decoding_strategy.change(\n",
    "        fn=lambda selection: gr.Slider(\n",
    "            visible=(\n",
    "                selection\n",
    "                in [\n",
    "                    \"contrastive_sampling\",\n",
    "                    \"beam_sampling\",\n",
    "                    \"Top P Sampling\",\n",
    "                    \"sampling_top_k\",\n",
    "                ]\n",
    "            )\n",
    "        ),\n",
    "        inputs=decoding_strategy,\n",
    "        outputs=temperature,\n",
    "    )\n",
    "    decoding_strategy.change(\n",
    "        fn=lambda selection: gr.Slider(visible=(selection in [\"Top P Sampling\"])),\n",
    "        inputs=decoding_strategy,\n",
    "        outputs=top_p,\n",
    "    )\n",
    "\n",
    "    gr.ChatInterface(\n",
    "        fn=model_inference,\n",
    "        chatbot=chatbot,\n",
    "        multimodal=True,\n",
    "        cache_examples=False,\n",
    "        additional_inputs=[\n",
    "            model_selector,\n",
    "            decoding_strategy,\n",
    "            temperature,\n",
    "            max_new_tokens,\n",
    "            repetition_penalty,\n",
    "            top_p,\n",
    "        ],   \n",
    "    )\n",
    "\n",
    "with gr.Blocks() as voice:   \n",
    "    with gr.Row():\n",
    "        input = gr.Audio(label=\"Voice Chat\", sources=\"microphone\", type=\"filepath\", waveform_options=False)\n",
    "        output = gr.Audio(label=\"MedFormer\", type=\"filepath\",\n",
    "                        interactive=False,\n",
    "                        autoplay=True,\n",
    "                        elem_classes=\"audio\")\n",
    "        gr.Interface(\n",
    "            fn=respond, \n",
    "            inputs=[input],\n",
    "                outputs=[output], live=True)\n",
    "\n",
    "\n",
    "\n",
    "# Define the Gradio interface for the RAG system\n",
    "with gr.Blocks(theme=gr.themes.Default(primary_hue=\"sky\")) as rag_interface:\n",
    "        vector_db = gr.State()\n",
    "        qa_chain = gr.State()\n",
    "        gr.HTML(\"<center><h1>RAG PDF chatbot</h1><center>\")\n",
    "        gr.Markdown(\"\"\"<b>Query your PDF documents!</b> This AI agent is designed to perform retrieval augmented generation (RAG) on PDF documents. The app is hosted on Hugging Face Hub for the sole purpose of demonstration. \\\n",
    "        <b>Please do not upload confidential documents.</b>\n",
    "        \"\"\")\n",
    "        with gr.Row():\n",
    "            with gr.Column(scale = 86):\n",
    "                gr.Markdown(\"<b>Step 1 - Upload PDF documents and Initialize RAG pipeline</b>\")\n",
    "                with gr.Row():\n",
    "                    document = gr.Files(height=300, file_count=\"multiple\", file_types=[\"pdf\"], interactive=True, label=\"Upload PDF documents\")\n",
    "                with gr.Row():\n",
    "                    db_btn = gr.Button(\"Create vector database\")\n",
    "                with gr.Row():\n",
    "                        db_progress = gr.Textbox(value=\"Not initialized\", show_label=False) # label=\"Vector database status\", \n",
    "                gr.Markdown(\"<style>body { font-size: 16px; }</style><b>Select Large Language Model (LLM) and input parameters</b>\")\n",
    "                with gr.Row():\n",
    "                    llm_btn = gr.Radio(list_llm_simple, label=\"Available LLMs\", value = list_llm_simple[0], type=\"index\") # info=\"Select LLM\", show_label=False\n",
    "                with gr.Row():\n",
    "                    with gr.Accordion(\"LLM input parameters\", open=False):\n",
    "                        with gr.Row():\n",
    "                            slider_temperature = gr.Slider(minimum = 0.01, maximum = 1.0, value=0.5, step=0.1, label=\"Temperature\", info=\"Controls randomness in token generation\", interactive=True)\n",
    "                        with gr.Row():\n",
    "                            slider_maxtokens = gr.Slider(minimum = 128, maximum = 9192, value=4096, step=128, label=\"Max New Tokens\", info=\"Maximum number of tokens to be generated\",interactive=True)\n",
    "                        with gr.Row():\n",
    "                                slider_topk = gr.Slider(minimum = 1, maximum = 10, value=3, step=1, label=\"top-k\", info=\"Number of tokens to select the next token from\", interactive=True)\n",
    "                with gr.Row():\n",
    "                    qachain_btn = gr.Button(\"Initialize Question Answering Chatbot\")\n",
    "                with gr.Row():\n",
    "                        llm_progress = gr.Textbox(value=\"Not initialized\", show_label=False) # label=\"Chatbot status\", \n",
    "\n",
    "            with gr.Column(scale = 200):\n",
    "                gr.Markdown(\"<b>Step 2 - Chat with your Document</b>\")\n",
    "                chatbot = gr.Chatbot(height=505)\n",
    "                with gr.Accordion(\"Relevent context from the source document\", open=False):\n",
    "                    with gr.Row():\n",
    "                        doc_source1 = gr.Textbox(label=\"Reference 1\", lines=2, container=True, scale=20)\n",
    "                        source1_page = gr.Number(label=\"Page\", scale=1)\n",
    "                    with gr.Row():\n",
    "                        doc_source2 = gr.Textbox(label=\"Reference 2\", lines=2, container=True, scale=20)\n",
    "                        source2_page = gr.Number(label=\"Page\", scale=1)\n",
    "                    with gr.Row():\n",
    "                        doc_source3 = gr.Textbox(label=\"Reference 3\", lines=2, container=True, scale=20)\n",
    "                        source3_page = gr.Number(label=\"Page\", scale=1)\n",
    "                with gr.Row():\n",
    "                    msg = gr.Textbox(placeholder=\"Ask a question\", container=True)\n",
    "                with gr.Row():\n",
    "                    submit_btn = gr.Button(\"Submit\")\n",
    "                    clear_btn = gr.ClearButton([msg, chatbot], value=\"Clear\")\n",
    "            \n",
    "        # Preprocessing events\n",
    "        db_btn.click(initialize_database, \\\n",
    "            inputs=[document], \\\n",
    "            outputs=[vector_db, db_progress])\n",
    "        qachain_btn.click(initialize_LLM, \\\n",
    "            inputs=[llm_btn, slider_temperature, slider_maxtokens, slider_topk, vector_db], \\\n",
    "            outputs=[qa_chain, llm_progress]).then(lambda:[None,\"\",0,\"\",0,\"\",0], \\\n",
    "            inputs=None, \\\n",
    "            outputs=[chatbot, doc_source1, source1_page, doc_source2, source2_page, doc_source3, source3_page], \\\n",
    "            queue=False)\n",
    "\n",
    "        # Chatbot events\n",
    "        msg.submit(conversation, \\\n",
    "            inputs=[qa_chain, msg, chatbot], \\\n",
    "            outputs=[qa_chain, msg, chatbot, doc_source1, source1_page, doc_source2, source2_page, doc_source3, source3_page], \\\n",
    "            queue=False)\n",
    "        submit_btn.click(conversation, \\\n",
    "            inputs=[qa_chain, msg, chatbot], \\\n",
    "            outputs=[qa_chain, msg, chatbot, doc_source1, source1_page, doc_source2, source2_page, doc_source3, source3_page], \\\n",
    "            queue=False)\n",
    "        clear_btn.click(lambda:[None,\"\",0,\"\",0,\"\",0], \\\n",
    "            inputs=None, \\\n",
    "            outputs=[chatbot, doc_source1, source1_page, doc_source2, source2_page, doc_source3, source3_page], \\\n",
    "            queue=False)\n",
    "\n",
    "with gr.Blocks(theme=theme, css=\"footer {visibility: hidden}textbox{resize:none}\", title=\"MedFormer\") as demo:\n",
    "    gr.Markdown(\"# MedFormer\")\n",
    "    gr.TabbedInterface([img, voice, rag_interface], ['💬 Super Chat', '🗣️ Voice Chat', '📄 RAG System'])\n",
    "\n",
    "demo.launch(share=True, debug=True)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "MedFormer-UI",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
