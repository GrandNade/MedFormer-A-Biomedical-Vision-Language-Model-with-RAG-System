# MedFormer: A Biomedical Vision-Language Model with RAG System
![medformer](https://github.com/Basel-anaya/MedFormer-lite/assets/81964452/569de6e0-b893-4897-8dc1-8d0392911b74)
This repository contains the code and resources for Medformer, a state-of-the-art medical visual language model developed by Basel. The project includes three main components:

1. **IDEFICS2-Fine-Tuning.ipynb**: A Jupyter Notebook for fine-tuning the IDEFICS2 vision language model (VLM) on medical data.
2. **LLaMA-3-Fine-Tuning.ipynb**: A Jupyter Notebook for fine-tuning the LLaMA-3 language model on medical data.
3. **MedFormer_UI.ipynb**: A Jupyter Notebook for the user interface (UI) of the Medformer project, powered by Gradio.

## Getting Started

To get started with Medformer, follow these steps:

1. Clone the repository:
```bash
git clone https://github.com/your-username/medformer.git
```
2. Install the required dependencies:
```bash  
pip install -r requirements.txt
```
5. Launch the desired Jupyter Notebook:

- For IDEFICS2 fine-tuning: `jupyter notebook IDEFICS2-Fine-Tuning.ipynb`
- For LLaMA-3 fine-tuning: `jupyter notebook LLaMA-3-Fine-Tuning.ipynb`
- For Medformer UI: `jupyter notebook MedFormer_UI.ipynb`

## Requirements

The required dependencies for this project are listed in the `requirements.txt` file. Make sure to install them before running the notebooks.

## Contributing

Contributions to Medformer are welcome! If you find any issues or have suggestions for improvements, please open an issue or submit a pull request.

## License

This project is licensed under the [MIT License](LICENSE).

## Acknowledgments

- [Hugging Face Transformers](https://github.com/huggingface/transformers)
- [Gradio](https://github.com/gradio-app/gradio)
- [PyTorch](https://github.com/pytorch/pytorch)
